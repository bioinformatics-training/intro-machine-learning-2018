# Solutions ch. 10 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  8.276665557
## 2  9.818781733
## 3  2.896829512
## 4  5.649952778
## 5  5.911325392
## 6  6.679188233
## 7  1.411144469
## 8  7.419640457
## 9  9.351408638
## 10 5.434029009
## 11 8.624343986
## 12 4.468753580
## 13 8.798766205
## 14 4.387454895
## 15 8.226068452
## 16 9.274108215
## 17 7.515504600
## 18 7.024145211
## 19 8.367584592
## 20 6.263937854
## 21 7.323886563
## 22 7.964641713
## 23 9.228238611
## 24 9.481182975
## 25 9.037548952
## 26 5.520836897
## 27 9.979675516
## 28 9.320858002
## 29 4.270469174
## 30 1.214889223
## 31 9.798893348
## 32 8.200720203
## 33 9.663312702
## 34 2.126113871
## 35 7.760783027
## 36 8.979599266
## 37 3.446221450
## 38 2.104860482
## 39 3.627129995
## 40 3.543940230
## 41 3.509965789
## 42 4.277146988
## 43 3.688490311
## 44 6.308122690
## 45 4.191501810
## 46 7.885615636
## 47 5.421972035
## 48 8.458577142
## 49 4.537760339
## 50 1.921624081
## 
## $covariate
##               [,1]
##  [1,] 68.503192742
##  [2,] 96.408474725
##  [3,]  8.391621220
##  [4,] 31.921966397
##  [5,] 34.943767893
##  [6,] 44.611555454
##  [7,]  1.991328713
##  [8,] 55.051064515
##  [9,] 87.448843522
## [10,] 29.528671270
## [11,] 74.379309197
## [12,] 19.969758554
## [13,] 77.418286726
## [14,] 19.249760453
## [15,] 67.668202170
## [16,] 86.009083176
## [17,] 56.482809386
## [18,] 49.338615942
## [19,] 70.016471902
## [20,] 39.236917440
## [21,] 53.639314394
## [22,] 63.435517624
## [23,] 85.160387866
## [24,] 89.892830607
## [25,] 81.677291053
## [26,] 30.479640048
## [27,] 99.593923404
## [28,] 86.878393893
## [29,] 18.236906966
## [30,]  1.475955825
## [31,] 96.018310846
## [32,] 67.251811852
## [33,] 93.379612383
## [34,]  4.520360194
## [35,] 60.229753191
## [36,] 80.633202987
## [37,] 11.876442283
## [38,]  4.430437647
## [39,] 13.156072004
## [40,] 12.559512351
## [41,] 12.319859839
## [42,] 18.293986353
## [43,] 13.604960777
## [44,] 39.792411868
## [45,] 17.568687419
## [46,] 62.182933954
## [47,] 29.397780751
## [48,] 71.547527262
## [49,] 20.591268898
## [50,]  3.692639107
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x29589d0>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x29589d0>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  68.503192742 8.276665557
## 2  96.408474725 9.818781733
## 3   8.391621220 2.896829512
## 4  31.921966397 5.649952778
## 5  34.943767893 5.911325392
## 6  44.611555454 6.679188233
## 7   1.991328713 1.411144469
## 8  55.051064515 7.419640457
## 9  87.448843522 9.351408638
## 10 29.528671270 5.434029009
## 11 74.379309197 8.624343986
## 12 19.969758554 4.468753580
## 13 77.418286726 8.798766205
## 14 19.249760453 4.387454895
## 15 67.668202170 8.226068452
## 16 86.009083176 9.274108215
## 17 56.482809386 7.515504600
## 18 49.338615942 7.024145211
## 19 70.016471902 8.367584592
## 20 39.236917440 6.263937854
## 21 53.639314394 7.323886563
## 22 63.435517624 7.964641713
## 23 85.160387866 9.228238611
## 24 89.892830607 9.481182975
## 25 81.677291053 9.037548952
## 26 30.479640048 5.520836897
## 27 99.593923404 9.979675516
## 28 86.878393893 9.320858002
## 29 18.236906966 4.270469174
## 30  1.475955825 1.214889223
## 31 96.018310846 9.798893348
## 32 67.251811852 8.200720203
## 33 93.379612383 9.663312702
## 34  4.520360194 2.126113871
## 35 60.229753191 7.760783027
## 36 80.633202987 8.979599266
## 37 11.876442283 3.446221450
## 38  4.430437647 2.104860482
## 39 13.156072004 3.627129995
## 40 12.559512351 3.543940230
## 41 12.319859839 3.509965789
## 42 18.293986353 4.277146988
## 43 13.604960777 3.688490311
## 44 39.792411868 6.308122690
## 45 17.568687419 4.191501810
## 46 62.182933954 7.885615636
## 47 29.397780751 5.421972035
## 48 71.547527262 8.458577142
## 49 20.591268898 4.537760339
## 50  3.692639107 1.921624081
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  8.275558346
## 2  9.814651163
## 3  2.911319293
## 4  5.651754196
## 5  5.911662607
## 6  6.677938685
## 7  1.401229785
## 8  7.418710068
## 9  9.355796626
## 10 5.437053085
## 11 8.624570782
## 12 4.468892747
## 13 8.800141129
## 14 4.386662264
## 15 8.224876021
## 16 9.278454123
## 17 7.514528035
## 18 7.023128114
## 19 8.366695795
## 20 6.262991303
## 21 7.322976009
## 22 7.963334988
## 23 9.232456125
## 24 9.484982304
## 25 9.040699743
## 26 5.523392017
## 27 9.966799069
## 28 9.325258576
## 29 4.268363523
## 30 1.226538885
## 31 9.795579765
## 32 8.199494094
## 33 9.664267243
## 34 2.127136907
## 35 7.759612523
## 36 8.982329381
## 37 3.447187819
## 38 2.104846873
## 39 3.624739967
## 40 3.542909219
## 41 3.509583308
## 42 4.275113199
## 43 3.685319500
## 44 6.307087536
## 45 4.188596618
## 46 7.884349019
## 47 5.425057128
## 48 8.457997761
## 49 4.538663140
## 50 1.912744309
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##               [,1]          [,2]           [,3]           [,4]
## [1,] -1.7652726696 0.34199142571  4.98207827473 -1.43457238798
## [2,]  0.1567701963 0.03490097561 -0.05273453905  0.02629524699
##                [,5]        [,6]          [,7]          [,8]        [,9]
## [1,] -0.78121552572 15.13734633 0.39651556518 -0.5846851374 13.82970628
## [2,]  0.04527727627 14.64088024 0.03575976976 -0.3108938853 15.52590086
##             [,10]
## [1,] 0.1227908447
## [2,] 0.0321190432
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  1.1150092224
##  [2,]  1.0041598434
##  [3,]  1.4882498891
##  [4,] -1.5618230756
##  [5,]  4.3206283232
##  [6,]  3.7000926096
##  [7,] -1.0927738218
##  [8,]  0.8042225274
##  [9,] -4.0882281555
## [10,] -0.1473344819
## [11,]  0.6184118057
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##                [,1]           [,2]         [,3]          [,4]
## [1,] -0.01713985128  0.06857356845  1.012611145 -1.0897694590
## [2,] -0.54859958636 -0.62080099390 -1.293464921  0.1332431093
##               [,5]         [,6]          [,7]          [,8]         [,9]
## [1,] -0.6042500032 0.8282413335 1.45143378232  0.4486988919 -1.079398722
## [2,] -0.1435279746 0.8435856112 0.07955037699 -0.9520090949  1.128606231
##              [,10]
## [1,] -0.1274058867
## [2,] -0.6014986864
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,]  0.48123769175
##  [2,]  0.35443675146
##  [3,]  1.23836204484
##  [4,] -0.06357470209
##  [5,]  0.46056345860
##  [6,]  1.90609717413
##  [7,] -1.72654535242
##  [8,] -0.15591738013
##  [9,]  0.68446498882
## [10,] -1.01487755015
## [11,]  0.36851478655
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0010052838891
## 2  -0.0005636476153
## 3  -0.0304843616254
## 4  -0.0033461240240
## 5  -0.0028984983487
## 6  -0.0019750563911
## 7  -0.5871529953374
## 8  -0.0014146821220
## 9  -0.0006832014928
## 10 -0.0037945935809
## 11 -0.0008867344680
## 12 -0.0072993140120
## 13 -0.0008338579365
## 14 -0.0077592648558
## 15 -0.0010243411078
## 16 -0.0007033283947
## 17 -0.0013582030105
## 18 -0.0016839210654
## 19 -0.0009722908650
## 20 -0.0024163393384
## 21 -0.0014743230997
## 22 -0.0011317152638
## 23 -0.0007153642379
## 24 -0.0006497390296
## 25 -0.0007664261230
## 26 -0.0036044227742
## 27 -0.0005228947233
## 28 -0.0006911350041
## 29 -0.0084826939913
## 30 -1.2513668008337
## 31 -0.0005686979179
## 32 -0.0010340852258
## 33 -0.0006031869259
## 34 -0.1028445945032
## 35 -0.0012272454238
## 36 -0.0007823680544
## 37 -0.0168131890266
## 38 -0.1071536084086
## 39 -0.0142821283611
## 40 -0.0153731193877
## 41 -0.0158528193884
## 42 -0.0084393257862
## 43 -0.0135451222000
## 44 -0.0023636904271
## 45 -0.0090158324183
## 46 -0.0011674216613
## 47 -0.0038221496163
## 48 -0.0009407658670
## 49 -0.0069343563112
## 50 -0.1557580353051
## 
## 
## $result.matrix
##                                         1
## error                     0.0004548883211
## reached.threshold         0.0063709885539
## steps                  2699.0000000000000
## Intercept.to.1layhid1    -1.7652726695759
## Input.to.1layhid1         0.1567701962513
## Intercept.to.1layhid2     0.3419914257107
## Input.to.1layhid2         0.0349009756125
## Intercept.to.1layhid3     4.9820782747264
## Input.to.1layhid3        -0.0527345390451
## Intercept.to.1layhid4    -1.4345723879834
## Input.to.1layhid4         0.0262952469881
## Intercept.to.1layhid5    -0.7812155257243
## Input.to.1layhid5         0.0452772762661
## Intercept.to.1layhid6    15.1373463323278
## Input.to.1layhid6        14.6408802449072
## Intercept.to.1layhid7     0.3965155651804
## Input.to.1layhid7         0.0357597697594
## Intercept.to.1layhid8    -0.5846851374362
## Input.to.1layhid8        -0.3108938853234
## Intercept.to.1layhid9    13.8297062772068
## Input.to.1layhid9        15.5259008647278
## Intercept.to.1layhid10    0.1227908446709
## Input.to.1layhid10        0.0321190432035
## Intercept.to.Output       1.1150092224026
## 1layhid.1.to.Output       1.0041598434197
## 1layhid.2.to.Output       1.4882498890793
## 1layhid.3.to.Output      -1.5618230755597
## 1layhid.4.to.Output       4.3206283231999
## 1layhid.5.to.Output       3.7000926096406
## 1layhid.6.to.Output      -1.0927738217713
## 1layhid.7.to.Output       0.8042225273818
## 1layhid.8.to.Output      -4.0882281555341
## 1layhid.9.to.Output      -0.1473344818853
## 1layhid.10.to.Output      0.6184118057280
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##              [,1]
##  [1,] 1.057339789
##  [2,] 1.994818072
##  [3,] 3.012407036
##  [4,] 3.995781024
##  [5,] 5.003983732
##  [6,] 5.999921492
##  [7,] 6.998965959
##  [8,] 7.998683587
##  [9,] 9.002880722
## [10,] 9.985720231
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1       1.057339789
## 2      4               2       1.994818072
## 3      9               3       3.012407036
## 4     16               4       3.995781024
## 5     25               5       5.003983732
## 6     36               6       5.999921492
## 7     49               7       6.998965959
## 8     64               8       7.998683587
## 9     81               9       9.002880722
## 10   100              10       9.985720231
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

